{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWFAts1vKCSq",
        "outputId": "6cb9458b-9353-477f-f767-dd11643ddafa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "!pip install nltk\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords') # Added to download stopwords\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TextPreprocessor:\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "        self.slang_dict = {\n",
        "            \"AFAIK\": \"As Far As I Know\",\n",
        "            \"AFK\": \"Away From Keyboard\",\n",
        "            \"ASAP\": \"As Soon As Possible\",\n",
        "            \"ATK\": \"At The Keyboard\",\n",
        "            \"ATM\": \"At The Moment\",\n",
        "            \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
        "            \"BAK\": \"Back At Keyboard\",\n",
        "            \"BBL\": \"Be Back Later\",\n",
        "            \"BBS\": \"Be Back Soon\",\n",
        "            \"BFN\": \"Bye For Now\",\n",
        "            \"B4N\": \"Bye For Now\",\n",
        "            \"BRB\": \"Be Right Back\",\n",
        "            \"BRT\": \"Be Right There\",\n",
        "            \"BTW\": \"By The Way\",\n",
        "            \"B4\": \"Before\",\n",
        "            \"CU\": \"See You\",\n",
        "            \"CUL8R\": \"See You Later\",\n",
        "            \"CYA\": \"See You\",\n",
        "            \"FAQ\": \"Frequently Asked Questions\",\n",
        "            \"FC\": \"Fingers Crossed\",\n",
        "            \"FWIW\": \"For What It's Worth\",\n",
        "            \"FYI\": \"For Your Information\",\n",
        "            \"GAL\": \"Get A Life\",\n",
        "            \"GG\": \"Good Game\",\n",
        "            \"GN\": \"Good Night\",\n",
        "            \"GMTA\": \"Great Minds Think Alike\",\n",
        "            \"GR8\": \"Great!\",\n",
        "            \"G9\": \"Genius\",\n",
        "            \"IC\": \"I See\",\n",
        "            \"ICQ\": \"I Seek you (also a chat program)\",\n",
        "            \"ILU\": \"I Love You\",\n",
        "            \"IMHO\": \"In My Honest/Humble Opinion\",\n",
        "            \"IMO\": \"In My Opinion\",\n",
        "            \"IOW\": \"In Other Words\",\n",
        "            \"IRL\": \"In Real Life\",\n",
        "            \"KISS\": \"Keep It Simple, Stupid\",\n",
        "            \"LDR\": \"Long Distance Relationship\",\n",
        "            \"LMAO\": \"Laugh My A** Off\",\n",
        "            \"LOL\": \"Laughing Out Loud\",\n",
        "            \"LTNS\": \"Long Time No See\",\n",
        "            \"L8R\": \"Later\",\n",
        "            \"MTE\": \"My Thoughts Exactly\",\n",
        "            \"M8\": \"Mate\",\n",
        "            \"NRN\": \"No Reply Necessary\",\n",
        "            \"OIC\": \"Oh I See\",\n",
        "            \"PITA\": \"Pain In The A**\",\n",
        "            \"PRT\": \"Party\",\n",
        "            \"PRW\": \"Parents Are Watching\",\n",
        "            \"QPSA?\": \"Que Pasa?\",\n",
        "            \"ROFL\": \"Rolling On The Floor Laughing\",\n",
        "            \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
        "            \"ROTFLMAO\": \"Rolling On The Floor Laughing My A** Off\",\n",
        "            \"SK8\": \"Skate\",\n",
        "            \"STATS\": \"Your sex and age\",\n",
        "            \"ASL\": \"Age, Sex, Location\",\n",
        "            \"THX\": \"Thank You\",\n",
        "            \"TTFN\": \"Ta-Ta For Now!\",\n",
        "            \"TTYL\": \"Talk To You Later\",\n",
        "            \"U\": \"You\",\n",
        "            \"U2\": \"You Too\",\n",
        "            \"U4E\": \"Yours For Ever\",\n",
        "            \"WB\": \"Welcome Back\",\n",
        "            \"WTF\": \"What The F...\",\n",
        "            \"WTG\": \"Way To Go!\",\n",
        "            \"WUF\": \"Where Are You From?\",\n",
        "            \"W8\": \"Wait...\",\n",
        "            \"7K\": \"Sick:-D Laugher\",\n",
        "            \"TFW\": \"That Feeling When\",\n",
        "            \"MFW\": \"My Face When\",\n",
        "            \"MRW\": \"My Reaction When\",\n",
        "            \"IFYP\": \"I Feel Your Pain\",\n",
        "            \"TNTL\": \"Trying Not To Laugh\",\n",
        "            \"JK\": \"Just Kidding\",\n",
        "            \"IDC\": \"I Don't Care\",\n",
        "            \"ILY\": \"I Love You\",\n",
        "            \"IMU\": \"I Miss You\",\n",
        "            \"ADIH\": \"Another Day In Hell\",\n",
        "            \"ZZZ\": \"Sleeping, Bored, Tired\",\n",
        "            \"WYWH\": \"Wish You Were Here\",\n",
        "            \"TIME\": \"Tears In My Eyes\",\n",
        "            \"BAE\": \"Before Anyone Else\",\n",
        "            \"FIMH\": \"Forever In My Heart\",\n",
        "            \"BSAAW\": \"Big Smile And A Wink\",\n",
        "            \"BWL\": \"Bursting With Laughter\",\n",
        "            \"BFF\": \"Best Friends Forever\",\n",
        "            \"CSL\": \"Can't Stop Laughing\"\n",
        "        }\n",
        "\n",
        "    def to_lower(self):\n",
        "        self.text = self.text.lower()\n",
        "\n",
        "    def remove_urls(self):\n",
        "        url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "        self.text = re.sub(url_pattern, '', self.text)\n",
        "\n",
        "    def remove_punc(self):\n",
        "        exclude = string.punctuation\n",
        "        self.text = self.text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "    def remove_selective_punc(self):\n",
        "        \"\"\"Remove all punctuation except brackets, semicolons, angle brackets, and equals sign using regex\"\"\"\n",
        "        self.text = re.sub(r'[^\\w\\s()\\[\\]{}]', '', self.text)\n",
        "        return self.text\n",
        "\n",
        "    def remove_numbers(self):\n",
        "        self.text = re.sub(r'\\d+', '', self.text)\n",
        "\n",
        "    def remove_abbr(self):\n",
        "        words = self.text.split(\" \")\n",
        "        processed_words = []\n",
        "        for word in words:\n",
        "            if word.upper() in self.slang_dict:\n",
        "                processed_words.append(self.slang_dict[word.upper()])\n",
        "            else:\n",
        "                processed_words.append(word)\n",
        "        self.text = \" \".join(processed_words)\n",
        "\n",
        "    def remove_stopwords(self):\n",
        "        stopwords = nltk.corpus.stopwords.words('english')\n",
        "        words = self.text.split()\n",
        "        filtered_words = [word for word in words if word.lower() not in stopwords]\n",
        "        self.text = ' '.join(filtered_words)\n",
        "\n",
        "    def clean_whitespace(self):\n",
        "        # Remove extra whitespace and clean up\n",
        "        self.text = ' '.join(self.text.split())\n",
        "\n",
        "    def gettext(self):\n",
        "        return self.text\n",
        "\n",
        "    def process_text(self):\n",
        "        # self.to_lower()\n",
        "        self.remove_urls()\n",
        "        self.remove_selective_punc()\n",
        "        # self.remove_numbers()\n",
        "        self.remove_abbr()\n",
        "        # self.remove_stopwords()\n",
        "        self.clean_whitespace()\n",
        "        return self.text"
      ],
      "metadata": {
        "id": "dzjdEqzpKlbG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, text, min_freq=3, tokenizer=word_tokenize):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.min_freq = min_freq\n",
        "        self.word2index = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}  # Add special tokens\n",
        "        self.index2word = {0: '<PAD>', 1: '<UNK>', 2: '<SOS>', 3: '<EOS>'}\n",
        "        self.tokens = []\n",
        "        self.numerical_text = []\n",
        "        self.text = text\n",
        "        self.word_freq = {}\n",
        "        self._vocab_built = False\n",
        "\n",
        "    def build_vocabulary(self):\n",
        "        if isinstance(self.text, str):\n",
        "            self.tokens = [self.tokenizer(self.text)]\n",
        "        else:\n",
        "            self.tokens = [self.tokenizer(t) for t in self.text]\n",
        "\n",
        "\n",
        "        for token_list in self.tokens:\n",
        "            for word in token_list:\n",
        "                self.word_freq[word] = self.word_freq.get(word, 0) + 1\n",
        "\n",
        "\n",
        "        index = 4\n",
        "        for word, freq in self.word_freq.items():\n",
        "            if freq >= self.min_freq:\n",
        "                self.word2index[word] = index\n",
        "                self.index2word[index] = word\n",
        "                index += 1\n",
        "\n",
        "        self._vocab_built = True\n",
        "        print(f\"Vocabulary built with {len(self.word2index)} tokens\")\n",
        "        print(f\"Most frequent words: {sorted(self.word_freq.items(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
        "        return self.word2index\n",
        "\n",
        "    def vectorize(self):\n",
        "        if not self._vocab_built:\n",
        "            self.build_vocabulary()\n",
        "\n",
        "        self.numerical_text = [\n",
        "            [self.word2index.get(token, 1) for token in tokens]  # Use 1 for <UNK>\n",
        "            for tokens in self.tokens\n",
        "        ]\n",
        "        return self.numerical_text\n",
        "\n",
        "    def devectorize(self, num_text):\n",
        "        if not self._vocab_built:\n",
        "            raise ValueError(\"Vocabulary not built yet. Call build_vocabulary() first.\")\n",
        "        words = list([self.index2word.get(idx, '<UNK>') for idx in num_text])\n",
        "        return \" \".join(words)\n",
        "\n",
        "    def zero_pad(self, max_len=None):\n",
        "        if not self.numerical_text:\n",
        "            self.vectorize()\n",
        "\n",
        "        if max_len is None:\n",
        "            max_len = max(len(seq) for seq in self.numerical_text)\n",
        "\n",
        "        padded = [\n",
        "            seq + [0] * (max_len - len(seq)) if len(seq) < max_len\n",
        "            else seq[:max_len]\n",
        "            for seq in self.numerical_text\n",
        "        ]\n",
        "        return padded\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return len(self.word2index)\n",
        "\n"
      ],
      "metadata": {
        "id": "3BzBJSuJKnKs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split: str, train_data, val_data, batch_size=32, context_size=16):\n",
        "    \"\"\"Improved batch generation with better error handling and bounds checking\"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "\n",
        "    if len(data) <= context_size:\n",
        "        print(f\"Warning: Data length ({len(data)}) <= context_size ({context_size})\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    max_start_index = len(data) - context_size - 1\n",
        "    if max_start_index <= 0:\n",
        "        print(f\"Error: Not enough data for context_size {context_size}\")\n",
        "        return None, None\n",
        "\n",
        "    starts = torch.randint(0, max_start_index, (batch_size,))\n",
        "\n",
        "    x = torch.stack([data[i:i+context_size] for i in starts])\n",
        "    y = torch.stack([data[i+1:i+context_size+1] for i in starts])\n",
        "\n",
        "\n",
        "    vocab_size = train_data.max().item() + 1 if len(train_data) > 0 else 1000\n",
        "    x = torch.clamp(x, 0, vocab_size - 1)\n",
        "    y = torch.clamp(y, 0, vocab_size - 1)\n",
        "\n",
        "\n",
        "    if (x == 0).all():\n",
        "        print(\"Warning: All-zero input batch detected!\")\n",
        "    if (y == 0).all():\n",
        "        print(\"Warning: All-zero target batch detected!\")\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "8JaWbkFsKzZ1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, num_heads, ff_size=256*2, dropout=0.1, device='cpu'):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_size, ff_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(ff_size, embed_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        # Pre-norm architecture\n",
        "        residual = x\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Self-attention with batch_first=True\n",
        "        attention, _ = self.attention(x, x, x, attn_mask=attn_mask, need_weights=False)\n",
        "        x = self.dropout(attention) + residual\n",
        "\n",
        "        # Feed forward\n",
        "        residual = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.dropout(x) + residual\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "1iZj_MaeK7eo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DisasterGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=512, num_heads=8, num_layers=3, context_size=128, dropout=0.1, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.num_heads = num_heads\n",
        "        self.num_layers = num_layers\n",
        "        self.context_size = context_size\n",
        "        self.device = device\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # CRITICAL FIX: Ensure embedding handles vocab_size correctly\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, context_size, embed_size), requires_grad=True)\n",
        "\n",
        "        ff_size = 4 * embed_size\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_size, num_heads, ff_size, dropout, device) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "        self.ln_final = nn.LayerNorm(embed_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"Proper weight initialization to prevent NaN\"\"\"\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.zeros_(module.bias)\n",
        "            elif isinstance(module, nn.Embedding):\n",
        "                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "                # Zero out padding token embedding\n",
        "                if hasattr(self, 'embedding') and module == self.embedding:\n",
        "                    with torch.no_grad():\n",
        "                        module.weight[0].fill_(0)\n",
        "            elif isinstance(module, nn.LayerNorm):\n",
        "                nn.init.ones_(module.weight)\n",
        "                nn.init.zeros_(module.bias)\n",
        "\n",
        "    def generate_causal_mask(self, size):\n",
        "        \"\"\"Generate causal mask for self-attention\"\"\"\n",
        "        mask = torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
        "        return mask.to(self.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = torch.clamp(x, 0, self.vocab_size - 1)\n",
        "\n",
        "        B, T = x.size()\n",
        "\n",
        "\n",
        "        token_emb = self.embedding(x)  # Shape: (B, T, embed_size)\n",
        "        token_emb = self.dropout(token_emb)\n",
        "\n",
        "\n",
        "        if T > self.positional_encoding.size(1):\n",
        "            # Handle sequences longer than context_size\n",
        "            pos_emb = self.positional_encoding[:, :1, :].repeat(1, T, 1)\n",
        "        else:\n",
        "            pos_emb = self.positional_encoding[:, :T, :]\n",
        "\n",
        "        pos_emb = pos_emb.to(self.device)\n",
        "\n",
        "\n",
        "        x = token_emb + pos_emb\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        # Generate causal mask\n",
        "        causal_mask = self.generate_causal_mask(T)\n",
        "\n",
        "        # Transformer blocks\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x, attn_mask=causal_mask)\n",
        "\n",
        "        # Final layer norm and output projection\n",
        "        x = self.ln_final(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "5mGS4oTPK9xZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < warmup_steps:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "OjVby59XLHzp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_training(model, lr=1e-4, device='cpu', warmup=500, total_steps=10000):\n",
        "    \"\"\"Setup training with improved hyperparameters\"\"\"\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        betas=(0.9, 0.95),\n",
        "        weight_decay=0.1,\n",
        "        eps=1e-8\n",
        "    )\n",
        "\n",
        "    # Use label smoothing to prevent overconfidence\n",
        "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1, ignore_index=0)\n",
        "\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup, total_steps=total_steps)\n",
        "    return optimizer, loss_fn, scheduler"
      ],
      "metadata": {
        "id": "tXKoMi9SLKp-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn, scheduler, train_data, val_data, device='cpu', epochs=10,\n",
        "          steps_per_epoch=500, patience=15, min_delta=1e-4, context_size=128, batch_size=32):\n",
        "    \"\"\"\n",
        "    Train the model with early stopping and NaN detection\n",
        "    \"\"\"\n",
        "    print(f\"Moving model to device: {device}\")\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    training_history = {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        valid_steps = 0\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "            try:\n",
        "                xb, yb = get_batch('train', train_data=train_data, val_data=val_data,\n",
        "                                 batch_size=batch_size, context_size=context_size)\n",
        "\n",
        "                if xb is None or yb is None:\n",
        "                    continue\n",
        "\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                logits = model(xb)\n",
        "                loss = loss_fn(logits.view(-1, logits.size(-1)), yb.view(-1))\n",
        "\n",
        "                # Check for NaN loss\n",
        "                if torch.isnan(loss) or torch.isinf(loss):\n",
        "                    print(f\"NaN/Inf loss detected at epoch {epoch+1}, step {step+1}\")\n",
        "                    continue\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping\n",
        "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                # Check for NaN gradients\n",
        "                nan_grads = False\n",
        "                for param in model.parameters():\n",
        "                    if param.grad is not None and (torch.isnan(param.grad).any() or torch.isinf(param.grad).any()):\n",
        "                        nan_grads = True\n",
        "                        break\n",
        "\n",
        "                if nan_grads:\n",
        "                    print(f\"NaN gradients detected at epoch {epoch+1}, step {step+1}\")\n",
        "                    optimizer.zero_grad()\n",
        "                    continue\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # Calculate training accuracy\n",
        "                with torch.no_grad():\n",
        "                    train_preds = torch.argmax(logits, dim=-1)\n",
        "                    # Only count non-padding tokens\n",
        "                    mask = (yb != 0)\n",
        "                    train_correct += ((train_preds == yb) & mask).sum().item()\n",
        "                    train_total += mask.sum().item()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                valid_steps += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in training step {step}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if valid_steps == 0:\n",
        "            print(f\"No valid training steps in epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        avg_loss = total_loss / valid_steps\n",
        "        train_accuracy = train_correct / train_total if train_total > 0 else 0.0\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_total_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        valid_val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                val_steps = min(50, len(val_data) // (batch_size * context_size))\n",
        "                for val_step in range(max(1, val_steps)):\n",
        "                    xv, yv = get_batch('val', train_data, val_data,\n",
        "                                     batch_size=batch_size, context_size=context_size)\n",
        "\n",
        "                    if xv is None or yv is None:\n",
        "                        continue\n",
        "\n",
        "                    xv, yv = xv.to(device), yv.to(device)\n",
        "                    val_logits = model(xv)\n",
        "                    val_loss = loss_fn(val_logits.view(-1, val_logits.size(-1)), yv.view(-1))\n",
        "\n",
        "                    if torch.isnan(val_loss) or torch.isinf(val_loss):\n",
        "                        continue\n",
        "\n",
        "                    val_total_loss += val_loss.item()\n",
        "                    valid_val_batches += 1\n",
        "\n",
        "                    preds = torch.argmax(val_logits, dim=-1)\n",
        "                    mask = (yv != 0)\n",
        "                    val_correct += ((preds == yv) & mask).sum().item()\n",
        "                    val_total += mask.sum().item()\n",
        "\n",
        "                if valid_val_batches > 0:\n",
        "                    avg_val_loss = val_total_loss / valid_val_batches\n",
        "                    val_accuracy = val_correct / val_total if val_total > 0 else 0.0\n",
        "                else:\n",
        "                    avg_val_loss = float('inf')\n",
        "                    val_accuracy = 0.0\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in validation: {e}\")\n",
        "                avg_val_loss = float('inf')\n",
        "                val_accuracy = 0.0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        # Store training history\n",
        "        training_history['train_loss'].append(avg_loss)\n",
        "        training_history['train_accuracy'].append(train_accuracy)\n",
        "        training_history['val_loss'].append(avg_val_loss)\n",
        "        training_history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_loss:.4f} | Train Acc: {train_accuracy:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if not (torch.isnan(torch.tensor(avg_val_loss)) or torch.isinf(torch.tensor(avg_val_loss))):\n",
        "            if avg_val_loss < best_val_loss - min_delta:\n",
        "                best_val_loss = avg_val_loss\n",
        "                patience_counter = 0\n",
        "                # Save best model\n",
        "                try:\n",
        "                    torch.save(model.state_dict(), 'best_model.pth')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving model: {e}\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    return training_history\n",
        "\n"
      ],
      "metadata": {
        "id": "-pJt43ixLT_5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_text(model, start_text, vocab_builder, max_length=50, device='cpu'):\n",
        "#     model.eval()\n",
        "#     tokens = vocab_builder.tokenizer(start_text)\n",
        "#     input_ids = torch.tensor([vocab_builder.word2index.get(token, 1) for token in tokens]).unsqueeze(0).to(device)  # Add batch dimension\n",
        "#     generated_text = start_text\n",
        "#     with torch.no_grad():\n",
        "#         for _ in range(max_length):\n",
        "#             input_ids = input_ids.to(device)\n",
        "#             logits = model(input_ids)\n",
        "#             next_token_logits = logits[:, -1, :]  # Get logits for the last token\n",
        "#             next_token_id = torch.argmax(next_token_logits, dim=-1).item()  # Get the predicted token ID\n",
        "\n",
        "#             if next_token_id == 0:  # If <PAD> token is predicted, stop generation\n",
        "#                 break\n",
        "\n",
        "#             generated_text += ' ' + vocab_builder.index2word.get(next_token_id, '<UNK>')\n",
        "#             input_ids = torch.cat([input_ids, torch.tensor([[next_token_id]], device=device)], dim=1)  # Append predicted token\n",
        "#     return generated_text.strip()\n",
        "def generate_text(model, start_text, vocab_builder, max_length=50, device='cpu', temperature=0.8):\n",
        "    \"\"\"Generate text with temperature sampling\"\"\"\n",
        "    model.eval()\n",
        "    tokens = vocab_builder.tokenizer(start_text)\n",
        "    input_ids = torch.tensor([vocab_builder.word2index.get(token, 1) for token in tokens]).unsqueeze(0).to(device)\n",
        "    generated_text = start_text\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            input_ids = input_ids.to(device)\n",
        "\n",
        "            # Ensure input_ids are within valid range\n",
        "            input_ids = torch.clamp(input_ids, 0, vocab_builder.get_vocab_size() - 1)\n",
        "\n",
        "            logits = model(input_ids)\n",
        "            next_token_logits = logits[:, -1, :] / temperature\n",
        "\n",
        "            # Apply softmax and sample\n",
        "            probs = F.softmax(next_token_logits, dim=-1)\n",
        "            next_token_id = torch.multinomial(probs, 1).item()\n",
        "\n",
        "            if next_token_id == 0 or next_token_id == 3:  # Stop on <PAD> or <EOS>\n",
        "                break\n",
        "\n",
        "            next_word = vocab_builder.index2word.get(next_token_id, '<UNK>')\n",
        "            generated_text += ' ' + next_word\n",
        "\n",
        "            # Append predicted token\n",
        "            input_ids = torch.cat([input_ids, torch.tensor([[next_token_id]], device=device)], dim=1)\n",
        "\n",
        "            # Truncate if too long to prevent memory issues\n",
        "            if input_ids.size(1) > model.context_size:\n",
        "                input_ids = input_ids[:, -model.context_size:]\n",
        "\n",
        "    return generated_text.strip()\n"
      ],
      "metadata": {
        "id": "dOZ0PzLjLe6Y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/bookcorpus.txt\",\"r\") as file:\n",
        "  text_data=file.read()"
      ],
      "metadata": {
        "id": "n_FW7slqLsGE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preprocessing text...\")\n",
        "text_preprocessor = TextPreprocessor(text_data)\n",
        "processed_text = text_preprocessor.process_text()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf1CcztCMIhQ",
        "outputId": "14e98601-eadc-4214-cada-8f28590e76b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing text...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_builder = Vocabulary(processed_text, min_freq=3)\n",
        "vocab_builder.build_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqleLsQVMMjk",
        "outputId": "28474fea-aa05-4007-9db8-9a05d595e96c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary built with 23126 tokens\n",
            "Most frequent words: [('SOS', 173131), ('EOS', 173131), ('the', 133942), ('to', 64348), ('and', 63800), ('a', 52518), ('of', 48494), ('i', 46303), ('he', 34845), ('was', 34052)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<PAD>': 0,\n",
              " '<UNK>': 1,\n",
              " '<SOS>': 2,\n",
              " '<EOS>': 3,\n",
              " 'SOS': 4,\n",
              " 'the': 5,\n",
              " 'halfling': 6,\n",
              " 'book': 7,\n",
              " 'one': 8,\n",
              " 'in': 9,\n",
              " 'fall': 10,\n",
              " 'of': 11,\n",
              " 'igneeria': 12,\n",
              " 'series': 13,\n",
              " 'copyright': 14,\n",
              " '2013': 15,\n",
              " 'all': 16,\n",
              " 'rights': 17,\n",
              " 'reserved': 18,\n",
              " 'EOS': 19,\n",
              " 'isbn': 20,\n",
              " 'for': 21,\n",
              " 'my': 22,\n",
              " 'family': 23,\n",
              " 'who': 24,\n",
              " 'encouraged': 25,\n",
              " 'me': 26,\n",
              " 'to': 27,\n",
              " 'never': 28,\n",
              " 'stop': 29,\n",
              " 'fighting': 30,\n",
              " 'dreams': 31,\n",
              " 'chapter': 32,\n",
              " '1': 33,\n",
              " 'summer': 34,\n",
              " 'vacations': 35,\n",
              " 'supposed': 36,\n",
              " 'be': 37,\n",
              " 'fun': 38,\n",
              " 'right': 39,\n",
              " 'i': 40,\n",
              " 'wish': 41,\n",
              " 'had': 42,\n",
              " 'a': 43,\n",
              " 'better': 44,\n",
              " 'answer': 45,\n",
              " 'that': 46,\n",
              " 'question': 47,\n",
              " 'new': 48,\n",
              " 'york': 49,\n",
              " 'is': 50,\n",
              " 'not': 51,\n",
              " 'place': 52,\n",
              " 'youd': 53,\n",
              " 'expect': 54,\n",
              " 'much': 55,\n",
              " 'happen': 56,\n",
              " 'its': 57,\n",
              " 'small': 58,\n",
              " 'quiet': 59,\n",
              " 'town': 60,\n",
              " 'kind': 61,\n",
              " 'where': 62,\n",
              " 'everyone': 63,\n",
              " 'knows': 64,\n",
              " 'your': 65,\n",
              " 'name': 66,\n",
              " 'parents': 67,\n",
              " 'wouldnt': 68,\n",
              " 'even': 69,\n",
              " 'care': 70,\n",
              " 'if': 71,\n",
              " 'you': 72,\n",
              " 'stayed': 73,\n",
              " 'out': 74,\n",
              " 'late': 75,\n",
              " 'with': 76,\n",
              " 'friends': 77,\n",
              " 'only': 78,\n",
              " 'because': 79,\n",
              " 'felt': 80,\n",
              " 'so': 81,\n",
              " 'safe': 82,\n",
              " 'comfy': 83,\n",
              " 'they': 84,\n",
              " 'dont': 85,\n",
              " 'know': 86,\n",
              " 'half': 87,\n",
              " 'it': 88,\n",
              " 'but': 89,\n",
              " 'do': 90,\n",
              " 'and': 91,\n",
              " 'want': 92,\n",
              " 'after': 93,\n",
              " 'dark': 94,\n",
              " 'reason': 95,\n",
              " 'why': 96,\n",
              " 'no': 97,\n",
              " 'this': 98,\n",
              " 'jason': 99,\n",
              " 'emily': 100,\n",
              " 'seth': 101,\n",
              " 'have': 102,\n",
              " 'kept': 103,\n",
              " 'way': 104,\n",
              " 'walked': 105,\n",
              " 'along': 106,\n",
              " 'empty': 107,\n",
              " 'road': 108,\n",
              " 'alone': 109,\n",
              " 'occasionally': 110,\n",
              " 'waving': 111,\n",
              " 'passing': 112,\n",
              " 'kids': 113,\n",
              " 'on': 114,\n",
              " 'bikes': 115,\n",
              " 'backpack': 116,\n",
              " 'was': 117,\n",
              " 'slung': 118,\n",
              " 'over': 119,\n",
              " 'shoulder': 120,\n",
              " 'filled': 121,\n",
              " 'writing': 122,\n",
              " 'books': 123,\n",
              " 'eyes': 124,\n",
              " 'shadowed': 125,\n",
              " 'watching': 126,\n",
              " 'every': 127,\n",
              " 'step': 128,\n",
              " 'usually': 129,\n",
              " 'more': 130,\n",
              " 'aware': 131,\n",
              " 'surroundings': 132,\n",
              " 'today': 133,\n",
              " 'tired': 134,\n",
              " 'didnt': 135,\n",
              " 'rammed': 136,\n",
              " 'into': 137,\n",
              " 'tree': 138,\n",
              " 'kicked': 139,\n",
              " 'rock': 140,\n",
              " 'grass': 141,\n",
              " 'sun': 142,\n",
              " 'starting': 143,\n",
              " 'set': 144,\n",
              " 'painting': 145,\n",
              " 'sky': 146,\n",
              " 'brilliant': 147,\n",
              " 'oranges': 148,\n",
              " 'reds': 149,\n",
              " 'slipped': 150,\n",
              " 'down': 151,\n",
              " 'allowing': 152,\n",
              " 'first': 153,\n",
              " 'stars': 154,\n",
              " 'peek': 155,\n",
              " 'from': 156,\n",
              " 'behind': 157,\n",
              " 'bright': 158,\n",
              " 'curtain': 159,\n",
              " 'remaining': 160,\n",
              " 'light': 161,\n",
              " 'cast': 162,\n",
              " 'shadows': 163,\n",
              " 'everything': 164,\n",
              " 'creating': 165,\n",
              " 'illusion': 166,\n",
              " 'there': 167,\n",
              " 'double': 168,\n",
              " 'world': 169,\n",
              " 'prepared': 170,\n",
              " 'go': 171,\n",
              " 'hours': 172,\n",
              " 'unreal': 173,\n",
              " 'silence': 174,\n",
              " 'made': 175,\n",
              " 'seem': 176,\n",
              " 'magical': 177,\n",
              " 'really': 178,\n",
              " 'phone': 179,\n",
              " 'buzzed': 180,\n",
              " 'awoke': 181,\n",
              " 'trance': 182,\n",
              " 'thumbed': 183,\n",
              " 'keypad': 184,\n",
              " 'opened': 185,\n",
              " 'message': 186,\n",
              " 'sent': 187,\n",
              " 'read': 188,\n",
              " 'whatcha': 189,\n",
              " 'doing': 190,\n",
              " 'flipped': 191,\n",
              " 'open': 192,\n",
              " 'pad': 193,\n",
              " 'wrote': 194,\n",
              " 'walking': 195,\n",
              " 'home': 196,\n",
              " 'shoved': 197,\n",
              " 'back': 198,\n",
              " 'pocket': 199,\n",
              " 'continued': 200,\n",
              " 'almost': 201,\n",
              " 'gone': 202,\n",
              " 'were': 203,\n",
              " 'appear': 204,\n",
              " 'looked': 205,\n",
              " 'at': 206,\n",
              " 'own': 207,\n",
              " 'shadow': 208,\n",
              " 'danced': 209,\n",
              " 'again': 210,\n",
              " 'as': 211,\n",
              " 'reply': 212,\n",
              " 'see': 213,\n",
              " 'anything': 214,\n",
              " 'meet': 215,\n",
              " 'glanced': 216,\n",
              " 'nearby': 217,\n",
              " 'woods': 218,\n",
              " 'ears': 219,\n",
              " 'heard': 220,\n",
              " 'nothing': 221,\n",
              " 'any': 222,\n",
              " 'movement': 223,\n",
              " 'hands': 224,\n",
              " 'shook': 225,\n",
              " 'slightly': 226,\n",
              " 'typed': 227,\n",
              " 'im': 228,\n",
              " 'fine': 229,\n",
              " 'his': 230,\n",
              " 'knew': 231,\n",
              " 'what': 232,\n",
              " 'would': 233,\n",
              " 'say': 234,\n",
              " 'already': 235,\n",
              " 'strangely': 236,\n",
              " 'maybe': 237,\n",
              " 'could': 238,\n",
              " 'stay': 239,\n",
              " 'sleep': 240,\n",
              " 'night': 241,\n",
              " 'or': 242,\n",
              " 'finish': 243,\n",
              " 'tonight': 244,\n",
              " 'watch': 245,\n",
              " 'mom': 246,\n",
              " 'turned': 247,\n",
              " 'corner': 248,\n",
              " 'house': 249,\n",
              " 'came': 250,\n",
              " 'view': 251,\n",
              " 'started': 252,\n",
              " 'climb': 253,\n",
              " 'hill': 254,\n",
              " 'when': 255,\n",
              " 'froze': 256,\n",
              " 'left': 257,\n",
              " 'eye': 258,\n",
              " 'saw': 259,\n",
              " 'outline': 260,\n",
              " 'creature': 261,\n",
              " 'heading': 262,\n",
              " 'through': 263,\n",
              " 'direction': 264,\n",
              " 'swore': 265,\n",
              " 'under': 266,\n",
              " 'breath': 267,\n",
              " 'took': 268,\n",
              " 'off': 269,\n",
              " 'feet': 270,\n",
              " 'crunched': 271,\n",
              " 'fallen': 272,\n",
              " 'branches': 273,\n",
              " 'leaves': 274,\n",
              " 'ahead': 275,\n",
              " 'Tears': 276,\n",
              " 'In': 277,\n",
              " 'My': 278,\n",
              " 'Eyes': 279,\n",
              " 'placed': 280,\n",
              " 'bag': 281,\n",
              " 'ground': 282,\n",
              " 'crossed': 283,\n",
              " 'legs': 284,\n",
              " 'grab': 285,\n",
              " 'stopped': 286,\n",
              " 'need': 287,\n",
              " 'tell': 288,\n",
              " 'others': 289,\n",
              " 'just': 290,\n",
              " 'lucky': 291,\n",
              " 'an': 292,\n",
              " 'easy': 293,\n",
              " 'take': 294,\n",
              " 'closed': 295,\n",
              " 'began': 296,\n",
              " 'mental': 297,\n",
              " 'countdown': 298,\n",
              " 'wind': 299,\n",
              " 'picked': 300,\n",
              " 'up': 301,\n",
              " 'around': 302,\n",
              " 'current': 303,\n",
              " 'appeared': 304,\n",
              " 'nowhere': 305,\n",
              " '5': 306,\n",
              " 'body': 307,\n",
              " 'feel': 308,\n",
              " 'hot': 309,\n",
              " 'like': 310,\n",
              " 'being': 311,\n",
              " 'hugged': 312,\n",
              " 'by': 313,\n",
              " 'hated': 314,\n",
              " 'part': 315,\n",
              " '4': 316,\n",
              " 'power': 317,\n",
              " 'surged': 318,\n",
              " 'freed': 319,\n",
              " 'human': 320,\n",
              " 'self': 321,\n",
              " 'shivers': 322,\n",
              " 'ran': 323,\n",
              " 'spine': 324,\n",
              " '3': 325,\n",
              " 'cold': 326,\n",
              " 'dipped': 327,\n",
              " 'ice': 328,\n",
              " 'water': 329,\n",
              " 'breeze': 330,\n",
              " 'harder': 331,\n",
              " '2': 332,\n",
              " 'hollow': 333,\n",
              " 'probably': 334,\n",
              " 'get': 335,\n",
              " 'courage': 336,\n",
              " 'died': 337,\n",
              " 'normal': 338,\n",
              " 'except': 339,\n",
              " 'different': 340,\n",
              " 'been': 341,\n",
              " 'still': 342,\n",
              " 'glowed': 343,\n",
              " 'sat': 344,\n",
              " 'meditation': 345,\n",
              " 'move': 346,\n",
              " 'monster': 347,\n",
              " 'clearly': 348,\n",
              " 'now': 349,\n",
              " 'stepped': 350,\n",
              " 'hunched': 351,\n",
              " 'touching': 352,\n",
              " 'curled': 353,\n",
              " 'front': 354,\n",
              " 'paws': 355,\n",
              " 'saliva': 356,\n",
              " 'dripped': 357,\n",
              " 'mouth': 358,\n",
              " 'beady': 359,\n",
              " 'black': 360,\n",
              " 'less': 361,\n",
              " 'scary': 362,\n",
              " 'exactly': 363,\n",
              " 'thrasher': 364,\n",
              " 'shiver': 365,\n",
              " 'thrashers': 366,\n",
              " 'most': 367,\n",
              " 'feral': 368,\n",
              " 'nasty': 369,\n",
              " 'monsters': 370,\n",
              " 'ive': 371,\n",
              " 'ever': 372,\n",
              " 'encountered': 373,\n",
              " 'sometimes': 374,\n",
              " 'travel': 375,\n",
              " 'hunt': 376,\n",
              " 'packs': 377,\n",
              " 'theyre': 378,\n",
              " 'awful': 379,\n",
              " 'extremely': 380,\n",
              " 'hard': 381,\n",
              " 'without': 382,\n",
              " 'their': 383,\n",
              " 'knowledge': 384,\n",
              " 'presence': 385,\n",
              " 'arrow': 386,\n",
              " 'bow': 387,\n",
              " 'aimed': 388,\n",
              " 'head': 389,\n",
              " 'couldnt': 390,\n",
              " 'let': 391,\n",
              " 'reach': 392,\n",
              " 'pulled': 393,\n",
              " 'string': 394,\n",
              " 'then': 395,\n",
              " 'these': 396,\n",
              " 'unless': 397,\n",
              " 'fire': 398,\n",
              " 'wasnt': 399,\n",
              " 'here': 400,\n",
              " 'few': 401,\n",
              " 'arrows': 402,\n",
              " 'best': 403,\n",
              " 'kill': 404,\n",
              " 'before': 405,\n",
              " 'realize': 406,\n",
              " 'youre': 407,\n",
              " 'instead': 408,\n",
              " 'lowered': 409,\n",
              " 'slowly': 410,\n",
              " 'crept': 411,\n",
              " 'until': 412,\n",
              " 'hideous': 413,\n",
              " 'claws': 414,\n",
              " 'hatred': 415,\n",
              " 'hate': 416,\n",
              " 'wonder': 417,\n",
              " 'how': 418,\n",
              " 'tolerate': 419,\n",
              " 'each': 420,\n",
              " 'other': 421,\n",
              " 'released': 422,\n",
              " 'whizzed': 423,\n",
              " 'silently': 424,\n",
              " 'howled': 425,\n",
              " 'pain': 426,\n",
              " 'dug': 427,\n",
              " 'fur': 428,\n",
              " 'whirled': 429,\n",
              " 'facing': 430,\n",
              " 'low': 431,\n",
              " 'growl': 432,\n",
              " 'sounded': 433,\n",
              " 'throat': 434,\n",
              " 'charged': 435,\n",
              " 'ducked': 436,\n",
              " 'slashed': 437,\n",
              " 'side': 438,\n",
              " 'winced': 439,\n",
              " 'shirt': 440,\n",
              " 'blue': 441,\n",
              " 'trickling': 442,\n",
              " 'wound': 443,\n",
              " 'yes': 444,\n",
              " 'blood': 445,\n",
              " 'threw': 446,\n",
              " 'hunting': 447,\n",
              " 'knife': 448,\n",
              " 'he': 449,\n",
              " 'landed': 450,\n",
              " 'yelped': 451,\n",
              " 'went': 452,\n",
              " 'limp': 453,\n",
              " 'pushed': 454,\n",
              " 'him': 455,\n",
              " 'grabbed': 456,\n",
              " 'familiar': 457,\n",
              " 'feeling': 458,\n",
              " 'wood': 459,\n",
              " 'boosting': 460,\n",
              " 'confidence': 461,\n",
              " 'slammed': 462,\n",
              " 'enough': 463,\n",
              " 'dirt': 464,\n",
              " 'vision': 465,\n",
              " 'spit': 466,\n",
              " 'clump': 467,\n",
              " 'wiry': 468,\n",
              " 'hair': 469,\n",
              " 'somehow': 470,\n",
              " 'found': 471,\n",
              " 'gasping': 472,\n",
              " 'searing': 473,\n",
              " 'raked': 474,\n",
              " 'leg': 475,\n",
              " 'against': 476,\n",
              " 'trying': 477,\n",
              " 'focus': 478,\n",
              " 'myself': 479,\n",
              " 'dull': 480,\n",
              " 'throb': 481,\n",
              " 'shin': 482,\n",
              " 'hauled': 483,\n",
              " 'looking': 484,\n",
              " 'face': 485,\n",
              " 'very': 486,\n",
              " 'unhappy': 487,\n",
              " 'haired': 488,\n",
              " 'boy': 489,\n",
              " 'sword': 490,\n",
              " 'gripped': 491,\n",
              " 'tightly': 492,\n",
              " 'clenched': 493,\n",
              " 'fingers': 494,\n",
              " 'look': 495,\n",
              " 'amusement': 496,\n",
              " 'many': 497,\n",
              " 'anger': 498,\n",
              " 'shone': 499,\n",
              " 'swallowed': 500,\n",
              " 'collected': 501,\n",
              " 'weapons': 502,\n",
              " 'daring': 503,\n",
              " 'hi': 504,\n",
              " 'unexpected': 505,\n",
              " 'glared': 506,\n",
              " 'definitely': 507,\n",
              " 'angry': 508,\n",
              " 'tried': 509,\n",
              " 'weight': 510,\n",
              " 'shot': 511,\n",
              " 'dead': 512,\n",
              " 'jazell': 513,\n",
              " 'yourself': 514,\n",
              " 'changed': 515,\n",
              " 'scolded': 516,\n",
              " 'lecture': 517,\n",
              " 'coming': 518,\n",
              " 'claw': 519,\n",
              " 'marks': 520,\n",
              " 'soaking': 521,\n",
              " 'pants': 522,\n",
              " 'panic': 523,\n",
              " 'bit': 524,\n",
              " 'hadnt': 525,\n",
              " 'shredded': 526,\n",
              " 'pieces': 527,\n",
              " 'send': 528,\n",
              " 'quick': 529,\n",
              " 'text': 530,\n",
              " 'showed': 531,\n",
              " 'help': 532,\n",
              " 'sighed': 533,\n",
              " 'annoyance': 534,\n",
              " 'mood': 535,\n",
              " 'strict': 536,\n",
              " 'serious': 537,\n",
              " 'normally': 538,\n",
              " 'hes': 539,\n",
              " 'fact': 540,\n",
              " 'we': 541,\n",
              " 'attack': 542,\n",
              " 'groups': 543,\n",
              " 'mostly': 544,\n",
              " 'our': 545,\n",
              " 'group': 546,\n",
              " 'disappeared': 547,\n",
              " 'has': 548,\n",
              " 'annoying': 549,\n",
              " 'skill': 550,\n",
              " 'able': 551,\n",
              " 'return': 552,\n",
              " 'having': 553,\n",
              " 'near': 554,\n",
              " 'which': 555,\n",
              " 'fair': 556,\n",
              " 'injured': 557,\n",
              " 'however': 558,\n",
              " 'stiffly': 559,\n",
              " 'make': 560,\n",
              " 'dormant': 561,\n",
              " 'once': 562,\n",
              " 'simultaneously': 563,\n",
              " 'returned': 564,\n",
              " 'reopened': 565,\n",
              " 'stood': 566,\n",
              " 'stretched': 567,\n",
              " 'chorus': 568,\n",
              " 'cracks': 569,\n",
              " 'cascading': 570,\n",
              " 'upwards': 571,\n",
              " 'straightened': 572,\n",
              " 'raised': 573,\n",
              " 'find': 574,\n",
              " 'thin': 575,\n",
              " 'red': 576,\n",
              " 'scratch': 577,\n",
              " 'injuries': 578,\n",
              " 'hunter': 579,\n",
              " 'form': 580,\n",
              " 'become': 581,\n",
              " 'severe': 582,\n",
              " 'quickly': 583,\n",
              " 'darker': 584,\n",
              " 'thicker': 585,\n",
              " 'skin': 586,\n",
              " 'sore': 587,\n",
              " 'purple': 588,\n",
              " 'checked': 589,\n",
              " 'might': 590,\n",
              " 'acquired': 591,\n",
              " 'tangle': 592,\n",
              " 'bunch': 593,\n",
              " 'bruises': 594,\n",
              " 'seemed': 595,\n",
              " 'trudged': 596,\n",
              " 'cozy': 597,\n",
              " 'paint': 598,\n",
              " 'white': 599,\n",
              " 'shutters': 600,\n",
              " 'helped': 601,\n",
              " 'relax': 602,\n",
              " 'door': 603,\n",
              " 'big': 604,\n",
              " 'fancy': 605,\n",
              " 'actually': 606,\n",
              " 'pretty': 607,\n",
              " 'plain': 608,\n",
              " 'thats': 609,\n",
              " 'loved': 610,\n",
              " 'two': 611,\n",
              " 'floors': 612,\n",
              " 'sized': 613,\n",
              " 'kitchen': 614,\n",
              " 'mini': 615,\n",
              " 'living': 616,\n",
              " 'room': 617,\n",
              " 'stairs': 618,\n",
              " 'beckoned': 619,\n",
              " 'though': 620,\n",
              " 'interested': 621,\n",
              " 'dinner': 622,\n",
              " 'cooking': 623,\n",
              " 'dad': 624,\n",
              " 'sitting': 625,\n",
              " 'table': 626,\n",
              " 'going': 627,\n",
              " 'usual': 628,\n",
              " 'paper': 629,\n",
              " 'work': 630,\n",
              " 'entered': 631,\n",
              " 'pushing': 632,\n",
              " 'glasses': 633,\n",
              " 'sweetheart': 634,\n",
              " 'finally': 635,\n",
              " 'asked': 636,\n",
              " 'giving': 637,\n",
              " 'warm': 638,\n",
              " 'smile': 639,\n",
              " 'kissed': 640,\n",
              " 'cheek': 641,\n",
              " 'moms': 642,\n",
              " 'toward': 643,\n",
              " 'yup': 644,\n",
              " 'dinners': 645,\n",
              " 'ready': 646,\n",
              " 'minutes': 647,\n",
              " 'called': 648,\n",
              " 'climbed': 649,\n",
              " 'eager': 650,\n",
              " 'collapse': 651,\n",
              " 'bed': 652,\n",
              " 'got': 653,\n",
              " 'painted': 654,\n",
              " 'green': 655,\n",
              " 'bookshelf': 656,\n",
              " 'overflowing': 657,\n",
              " 'desk': 658,\n",
              " 'piled': 659,\n",
              " 'high': 660,\n",
              " 'homework': 661,\n",
              " 'random': 662,\n",
              " 'drawings': 663,\n",
              " 'shoes': 664,\n",
              " 'headed': 665,\n",
              " 'handed': 666,\n",
              " 'some': 667,\n",
              " 'dishes': 668,\n",
              " 'utensils': 669,\n",
              " 'plate': 670,\n",
              " 'frowned': 671,\n",
              " 'pointed': 672,\n",
              " 'scratched': 673,\n",
              " 'happened': 674,\n",
              " 'studied': 675,\n",
              " 'tripped': 676,\n",
              " 'crack': 677,\n",
              " 'scraped': 678,\n",
              " 'said': 679,\n",
              " 'flatly': 680,\n",
              " 'lie': 681,\n",
              " 'rolling': 682,\n",
              " 'tongue': 683,\n",
              " 'easily': 684,\n",
              " 'last': 685,\n",
              " 'dish': 686,\n",
              " 'chair': 687,\n",
              " 'chuckled': 688,\n",
              " 'clumsy': 689,\n",
              " 'surprised': 690,\n",
              " 'close': 691,\n",
              " 'believed': 692,\n",
              " 'long': 693,\n",
              " 'explain': 694,\n",
              " 'million': 695,\n",
              " 'cuts': 696,\n",
              " 'gained': 697,\n",
              " 'creatures': 698,\n",
              " 'truth': 699,\n",
              " 'great': 700,\n",
              " 'balance': 701,\n",
              " 'little': 702,\n",
              " 'believe': 703,\n",
              " 'food': 704,\n",
              " 'straight': 705,\n",
              " 'hopefully': 706,\n",
              " 'did': 707,\n",
              " 'nights': 708,\n",
              " 'come': 709,\n",
              " 'cause': 710,\n",
              " 'trouble': 711,\n",
              " 'rest': 712,\n",
              " 'rolled': 713,\n",
              " 'burying': 714,\n",
              " 'pillow': 715,\n",
              " 'managed': 716,\n",
              " 'think': 717,\n",
              " 'about': 718,\n",
              " 'something': 719,\n",
              " 'than': 720,\n",
              " 'bump': 721,\n",
              " 'drifted': 722,\n",
              " 'morning': 723,\n",
              " 'note': 724,\n",
              " 'saying': 725,\n",
              " 'eat': 726,\n",
              " 'speed': 727,\n",
              " 'breakfast': 728,\n",
              " 'restaurant': 729,\n",
              " 'chained': 730,\n",
              " 'bike': 731,\n",
              " 'plastic': 732,\n",
              " 'occupied': 733,\n",
              " 'slid': 734,\n",
              " 'next': 735,\n",
              " 'talking': 736,\n",
              " 'she': 737,\n",
              " 'recently': 738,\n",
              " 'her': 739,\n",
              " 'pretending': 740,\n",
              " 'fascinated': 741,\n",
              " 'rant': 742,\n",
              " 'midsentence': 743,\n",
              " 'noticed': 744,\n",
              " 'beside': 745,\n",
              " 'exclaimed': 746,\n",
              " 'true': 747,\n",
              " 'yesterday': 748,\n",
              " 'shooting': 749,\n",
              " 'thanks': 750,\n",
              " 'well': 751,\n",
              " 'thought': 752,\n",
              " 'sharply': 753,\n",
              " 'gotten': 754,\n",
              " 'seriously': 755,\n",
              " 'hurt': 756,\n",
              " 'plus': 757,\n",
              " 'bet': 758,\n",
              " 'us': 759,\n",
              " 'them': 760,\n",
              " 'too': 761,\n",
              " 'huffed': 762,\n",
              " 'brown': 763,\n",
              " 'curls': 764,\n",
              " 'framed': 765,\n",
              " 'bounced': 766,\n",
              " 'playfully': 767,\n",
              " 'silent': 768,\n",
              " 'talked': 769,\n",
              " 'talkative': 770,\n",
              " 'friendly': 771,\n",
              " 'person': 772,\n",
              " 'type': 773,\n",
              " 'traced': 774,\n",
              " 'puddle': 775,\n",
              " 'avoiding': 776,\n",
              " 'everyones': 777,\n",
              " 'contact': 778,\n",
              " 'stared': 779,\n",
              " 'patted': 780,\n",
              " 'arm': 781,\n",
              " 'okay': 782,\n",
              " 'arent': 783,\n",
              " 'mad': 784,\n",
              " 'shrugged': 785,\n",
              " 'guess': 786,\n",
              " 'perked': 787,\n",
              " 'makes': 788,\n",
              " 'mistakes': 789,\n",
              " 'grunted': 790,\n",
              " 'himself': 791,\n",
              " 'hey': 792,\n",
              " 'havent': 793,\n",
              " 'done': 794,\n",
              " 'stupid': 795,\n",
              " 'remember': 796,\n",
              " 'swamp': 797,\n",
              " 'troll': 798,\n",
              " 'snickered': 799,\n",
              " 'punched': 800,\n",
              " 'nag': 801,\n",
              " 'throwing': 802,\n",
              " 'narrowed': 803,\n",
              " 'accident': 804,\n",
              " 'run': 805,\n",
              " 'alright': 806,\n",
              " 'understand': 807,\n",
              " 'weve': 808,\n",
              " 'foolish': 809,\n",
              " 'things': 810,\n",
              " 'lets': 811,\n",
              " 'add': 812,\n",
              " 'list': 813,\n",
              " 'nodded': 814,\n",
              " 'smirks': 815,\n",
              " 'wondering': 816,\n",
              " 'those': 817,\n",
              " 'buffoons': 818,\n",
              " 'granted': 819,\n",
              " 'werent': 820,\n",
              " 'day': 821,\n",
              " 'mystery': 822,\n",
              " 'lot': 823,\n",
              " 'quite': 824,\n",
              " 'sense': 825,\n",
              " 'four': 826,\n",
              " 'rambling': 827,\n",
              " 'halloween': 828,\n",
              " 'ms': 829,\n",
              " 'sudden': 830,\n",
              " 'invisible': 831,\n",
              " 'object': 832,\n",
              " 'shrieked': 833,\n",
              " 'pinned': 834,\n",
              " 'forward': 835,\n",
              " 'branch': 836,\n",
              " 'protect': 837,\n",
              " 'should': 838,\n",
              " 'air': 839,\n",
              " 'collided': 840,\n",
              " 'snapped': 841,\n",
              " 'dropped': 842,\n",
              " 'amazement': 843,\n",
              " 'plowed': 844,\n",
              " 'screamed': 845,\n",
              " 'spitting': 846,\n",
              " 'twigs': 847,\n",
              " 'terrified': 848,\n",
              " 'clue': 849,\n",
              " 'fight': 850,\n",
              " 'none': 851,\n",
              " 'seths': 852,\n",
              " 'hit': 853,\n",
              " 'attacker': 854,\n",
              " 'hold': 855,\n",
              " 'yelled': 856,\n",
              " 'vanished': 857,\n",
              " 'dragged': 858,\n",
              " 'away': 859,\n",
              " 'yell': 860,\n",
              " 'curse': 861,\n",
              " 'words': 862,\n",
              " 'while': 863,\n",
              " 'spotted': 864,\n",
              " 'blacked': 865,\n",
              " 'sleeping': 866,\n",
              " 'fell': 867,\n",
              " 'wooden': 868,\n",
              " 'reached': 869,\n",
              " 'quiver': 870,\n",
              " 'full': 871,\n",
              " 'feathered': 872,\n",
              " 'strapped': 873,\n",
              " 'finger': 874,\n",
              " 'smooth': 875,\n",
              " 'crashing': 876,\n",
              " 'smirked': 877,\n",
              " 'giggled': 878,\n",
              " 'knowing': 879,\n",
              " 'giggling': 880,\n",
              " 'ago': 881,\n",
              " 'piece': 882,\n",
              " 'widened': 883,\n",
              " 'laughed': 884,\n",
              " 'shock': 885,\n",
              " 'poke': 886,\n",
              " 'smiled': 887,\n",
              " 'neon': 888,\n",
              " 'examined': 889,\n",
              " 'wearing': 890,\n",
              " 'boots': 891,\n",
              " 'tight': 892,\n",
              " 'sort': 893,\n",
              " 'cloth': 894,\n",
              " 'thick': 895,\n",
              " 'woven': 896,\n",
              " 'jacket': 897,\n",
              " 'shielding': 898,\n",
              " 'october': 899,\n",
              " 'realized': 900,\n",
              " 'also': 901,\n",
              " 'outfit': 902,\n",
              " 'change': 903,\n",
              " 'leather': 904,\n",
              " 'top': 905,\n",
              " 'short': 906,\n",
              " 'cloak': 907,\n",
              " 'hood': 908,\n",
              " 'belt': 909,\n",
              " 'beautiful': 910,\n",
              " 'steel': 911,\n",
              " 'ornamental': 912,\n",
              " 'hilt': 913,\n",
              " 'swinging': 914,\n",
              " 'sheath': 915,\n",
              " 'oh': 916,\n",
              " 'bad': 917,\n",
              " 'rambled': 918,\n",
              " 'resting': 919,\n",
              " 'hip': 920,\n",
              " 'blade': 921,\n",
              " 'putting': 922,\n",
              " 'such': 923,\n",
              " 'dangerous': 924,\n",
              " 'anyones': 925,\n",
              " 'certainly': 926,\n",
              " 'footsteps': 927,\n",
              " 'running': 928,\n",
              " 'fitting': 929,\n",
              " 'robe': 930,\n",
              " 'stunning': 931,\n",
              " 'deep': 932,\n",
              " 'trim': 933,\n",
              " 'gold': 934,\n",
              " 'embroidery': 935,\n",
              " 'dangling': 936,\n",
              " 'visible': 937,\n",
              " 'standing': 938,\n",
              " 'pink': 939,\n",
              " 'isnt': 940,\n",
              " 'cool': 941,\n",
              " 'spun': 942,\n",
              " 'color': 943,\n",
              " 'gleaming': 944,\n",
              " 'deadly': 945,\n",
              " 'both': 946,\n",
              " 'can': 947,\n",
              " 'trust': 948,\n",
              " 'sharp': 949,\n",
              " 'cant': 950,\n",
              " 'either': 951,\n",
              " 'crossing': 952,\n",
              " 'arms': 953,\n",
              " 'arming': 954,\n",
              " 'gasped': 955,\n",
              " 'yeah': 956,\n",
              " 'ignoring': 957,\n",
              " 'are': 958,\n",
              " 'crashed': 959,\n",
              " 'trees': 960,\n",
              " 'panting': 961,\n",
              " 'wavy': 962,\n",
              " 'layered': 963,\n",
              " 'tunic': 964,\n",
              " 'mine': 965,\n",
              " 'taken': 966,\n",
              " 'huge': 967,\n",
              " 'backwards': 968,\n",
              " 'appearance': 969,\n",
              " 'whats': 970,\n",
              " 'demanded': 971,\n",
              " 'flickering': 972,\n",
              " 'strange': 973,\n",
              " 'appearances': 974,\n",
              " 'stumped': 975,\n",
              " 'lip': 976,\n",
              " 'forgot': 977,\n",
              " 'gestured': 978,\n",
              " 'grinning': 979,\n",
              " 'mischievously': 980,\n",
              " 'hanging': 981,\n",
              " 'multitude': 982,\n",
              " 'knives': 983,\n",
              " 'sleeve': 984,\n",
              " 'another': 985,\n",
              " 'huh': 986,\n",
              " 'groaned': 987,\n",
              " 'stomping': 988,\n",
              " 'foot': 989,\n",
              " 'aw': 990,\n",
              " 'whispered': 991,\n",
              " 'hand': 992,\n",
              " 'girl': 993,\n",
              " 'issues': 994,\n",
              " 'angrily': 995,\n",
              " 'suddenly': 996,\n",
              " 'furry': 997,\n",
              " 'wicked': 998,\n",
              " 'soon': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_text = vocab_builder.vectorize()\n",
        "data = torch.tensor(numeric_text[0])\n",
        "data = torch.clamp(data, 0, vocab_builder.get_vocab_size() - 1)\n",
        "data = data.flatten()"
      ],
      "metadata": {
        "id": "Tja5TtbeModH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = 0.8\n",
        "split_idx = int(len(data) * train_split)\n",
        "train_data = data[:split_idx]\n",
        "val_data = data[split_idx:]"
      ],
      "metadata": {
        "id": "-vexfjK1MzjP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "qaPnUskbNBl1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DisasterGPT(\n",
        "        vocab_size=vocab_builder.get_vocab_size(),\n",
        "        embed_size=256,  # Reduced for stability\n",
        "        num_heads=8,\n",
        "        num_layers=3,\n",
        "        context_size=128,\n",
        "        dropout=0.1,\n",
        "        device=device\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "id": "bH3TXqlkM51Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_builder.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbCoetSwNYw-",
        "outputId": "0e25214c-bf13-421a-f9f2-ac577ca89a94"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23126"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer, loss_fn, scheduler = setup_training(model, lr=1e-4, device=device)\n",
        "print(\"Starting training...\")\n",
        "history = train(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_fn,\n",
        "        scheduler=scheduler,\n",
        "        train_data=train_data,\n",
        "        val_data=val_data,\n",
        "        device=device,\n",
        "        epochs=2,\n",
        "        steps_per_epoch=500,\n",
        "        context_size=256,\n",
        "        batch_size=64  # Reduced for stability\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "7aGxN3HnM_xc",
        "outputId": "af1a5fa1-dfba-4eed-f33b-666af9befef1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Moving model to device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-39-4176557319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = train(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-9-1017917751.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, scheduler, train_data, val_data, device, epochs, steps_per_epoch, patience, min_delta, context_size, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mnan_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                         \u001b[0mnan_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text(prompt):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Instantiate the model first\n",
        "    loaded_model = DisasterGPT(\n",
        "        vocab_size=vocab_builder.get_vocab_size(),\n",
        "        embed_size=256,\n",
        "        num_heads=8,\n",
        "        num_layers=3,\n",
        "        context_size=128,\n",
        "        dropout=0.1,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Load the state dictionary\n",
        "    loaded_mode=torch.load(\"/content/finetuned_model.pth\", weights_only=False)\n",
        "    loaded_model.eval()\n",
        "    loaded_model.to(device)\n",
        "    generated_text = generate_text(loaded_model, prompt, vocab_builder, max_length=50, device=device)\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "G2LXy4kVNHAw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkV2XkIyOZjz",
        "outputId": "05550b17-6ce9-478f-a11f-b6daac1b87b8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
        "import torch\n",
        "import torch._dynamo\n",
        "torch._dynamo.reset()\n",
        "\n",
        "# Define input shape: (batch_size, sequence_length)\n",
        "batch_size = 64\n",
        "context_size = 256\n",
        "\n",
        "# Create a dummy input\n",
        "dummy_input = torch.randint(0, model.vocab_size, (batch_size, context_size)).to(model.device)\n",
        "\n",
        "# Compute parameter count\n",
        "print(parameter_count_table(model))\n",
        "\n",
        "# Compute FLOPs\n",
        "flops = FlopCountAnalysis(model, dummy_input)\n",
        "print(f\"FLOPs: {flops.total():,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqkvHZ5IOcHY",
        "outputId": "2b10a5dd-a6a6-48e9-bcb1-f5626209c205"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::embedding encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::repeat encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 7 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::triu encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::masked_fill_ encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::div encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::unflatten encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 12 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::scaled_dot_product_attention encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::gelu encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "transformer_blocks.0.attention.out_proj, transformer_blocks.1.attention.out_proj, transformer_blocks.2.attention.out_proj\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| name                              | #elements or shape   |\n",
            "|:----------------------------------|:---------------------|\n",
            "| model                             | 14.3M                |\n",
            "|  positional_encoding              |  (1, 128, 256)       |\n",
            "|  embedding                        |  5.9M                |\n",
            "|   embedding.weight                |   (23126, 256)       |\n",
            "|  transformer_blocks               |  2.4M                |\n",
            "|   transformer_blocks.0            |   0.8M               |\n",
            "|    transformer_blocks.0.attention |    0.3M              |\n",
            "|    transformer_blocks.0.ff        |    0.5M              |\n",
            "|    transformer_blocks.0.norm1     |    0.5K              |\n",
            "|    transformer_blocks.0.norm2     |    0.5K              |\n",
            "|   transformer_blocks.1            |   0.8M               |\n",
            "|    transformer_blocks.1.attention |    0.3M              |\n",
            "|    transformer_blocks.1.ff        |    0.5M              |\n",
            "|    transformer_blocks.1.norm1     |    0.5K              |\n",
            "|    transformer_blocks.1.norm2     |    0.5K              |\n",
            "|   transformer_blocks.2            |   0.8M               |\n",
            "|    transformer_blocks.2.attention |    0.3M              |\n",
            "|    transformer_blocks.2.ff        |    0.5M              |\n",
            "|    transformer_blocks.2.norm1     |    0.5K              |\n",
            "|    transformer_blocks.2.norm2     |    0.5K              |\n",
            "|  fc_out                           |  5.9M                |\n",
            "|   fc_out.weight                   |   (23126, 256)       |\n",
            "|   fc_out.bias                     |   (23126,)           |\n",
            "|  ln_final                         |  0.5K                |\n",
            "|   ln_final.weight                 |   (256,)             |\n",
            "|   ln_final.bias                   |   (256,)             |\n",
            "FLOPs: 135,798,980,608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/finetuning.txt\", \"r\") as file:\n",
        "  finetuning_text=file.read()"
      ],
      "metadata": {
        "id": "DRljWHlIVxXl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZy-P2LSbQae"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetuning(model,text):\n",
        "  finetuning_text_preprocessor=TextPreprocessor(text)\n",
        "  text=finetuning_text_preprocessor.process_text()\n",
        "  ft_tokens=vocab_builder.tokenizer(text)\n",
        "  ft_numerical=[vocab_builder.word2index.get(token, 1) for token in ft_tokens]\n",
        "  ft_data = torch.tensor(ft_numerical)\n",
        "  ft_data = torch.clamp(ft_data, 0, vocab_builder.get_vocab_size() - 1)\n",
        "  ft_train_split = 0.8\n",
        "  ft_split_idx = int(len(ft_data) * ft_train_split)\n",
        "  ft_train_data = ft_data[:ft_split_idx]\n",
        "  ft_val_data = ft_data[ft_split_idx:]\n",
        "  device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  optimizer, loss_fn, scheduler = setup_training(model, lr=1e-4, device=device)\n",
        "  history=train(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_fn,\n",
        "        scheduler=scheduler,\n",
        "        train_data=ft_train_data,\n",
        "        val_data=ft_val_data,\n",
        "        device=device,\n",
        "        epochs=5,\n",
        "        steps_per_epoch=100,\n",
        "        context_size=256,\n",
        "        batch_size=32 # Reduced for stability\n",
        "    )\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JQlnktlXbqwS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=finetuning(model, finetuning_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsovdy-fxmq",
        "outputId": "c1d47429-a1aa-4cc6-e597-3aaadfb8740d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device: cuda\n",
            "Epoch 1/5 | Train Loss: 5.6736 | Train Acc: 0.2531 | Val Loss: 6.0577 | Val Acc: 0.2604\n",
            "Epoch 2/5 | Train Loss: 4.7778 | Train Acc: 0.3538 | Val Loss: 5.8509 | Val Acc: 0.2692\n",
            "Epoch 3/5 | Train Loss: 4.4790 | Train Acc: 0.3715 | Val Loss: 5.7924 | Val Acc: 0.2791\n",
            "Epoch 4/5 | Train Loss: 4.2487 | Train Acc: 0.3887 | Val Loss: 5.7796 | Val Acc: 0.2726\n",
            "Epoch 5/5 | Train Loss: 4.0410 | Train Acc: 0.4091 | Val Loss: 6.1833 | Val Acc: 0.2539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'finetuned_model.pth')"
      ],
      "metadata": {
        "id": "OoKNGv-GgUsV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hargiAuagXnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_text(\"My house is burning?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpBjiUJMVsDr",
        "outputId": "bf1878ad-ecfd-4e7c-d61f-0207c3ac3a01"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My house is burning? bee blankets costume malachi retrieved wages jfk twill tomato anticipation showering dias earpiece speaks promoting copious analyze mint posted cut passageway hotels amateur funniest gouged extending receptions quantity navigate drain cancel bloodless doganoglu dangerous command wickedly poetic mayday birthday orleans obsessed cheering openly mercias formation octave client ghastly deigned trance\n"
          ]
        }
      ]
    }
  ]
}